# ğŸ§  AI Knowledge Auditor â€“ MVP v1.6
# A chatbot that audits answers from PDF content using keyword matching and a trust score

import streamlit as st
import fitz  # PyMuPDF: Used to read text from PDFs
import nltk
import re
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize

# ğŸ“¦ Download NLTK data required for tokenizing and stopword filtering
nltk.download('punkt')
nltk.download('stopwords')

# ğŸš€ Configure Streamlit page layout and metadata
st.set_page_config(page_title="AI Knowledge Auditor", page_icon="ğŸ§ ", layout="centered")

# ğŸ“Œ Sidebar with usage instructions
with st.sidebar:
    st.title("ğŸ“š How It Works")
    st.markdown("""
    1. Upload a PDF  
    2. Ask a question about its content  
    3. We'll highlight a relevant passage and calculate a **Trust Score**  
    ---
    Trust Score reflects how well the PDF supports the answer based on keyword overlap.
    """)

# ğŸ§  App Title and Description
st.title("ğŸ§  AI Knowledge Auditor")
st.caption("Upload a PDF and ask a question. Weâ€™ll evaluate the accuracy of the answer using the document.")

# ğŸ’¬ Initialize message history in session state
if "messages" not in st.session_state:
    st.session_state.messages = []

# ğŸ“„ PDF file uploader
uploaded_pdf = st.file_uploader("ğŸ“„ Upload a PDF", type=["pdf"])

# ğŸ” Extract text from all pages of a PDF using PyMuPDF
def extract_text_from_pdf(file):
    with fitz.open(stream=file.read(), filetype="pdf") as doc:
        return "\n".join(page.get_text() for page in doc)

# ğŸ§  Get keywords from a question by tokenizing and removing stopwords
def get_keywords(text):
    stop_words = set(stopwords.words("english"))
    tokens = word_tokenize(text.lower())
    return [word for word in tokens if word.isalnum() and word not in stop_words]

# ğŸ” Search for the best-matching chunk of PDF text based on keyword overlap
def find_best_chunk(question, context, window=600):
    keywords = get_keywords(question)
    chunks = [context[i:i+window] for i in range(0, len(context), window)]
    best_chunk, max_matches = "", 0
    for chunk in chunks:
        match_count = sum(1 for kw in keywords if kw in chunk.lower())
        if match_count > max_matches:
            best_chunk = chunk
            max_matches = match_count
    return best_chunk, max_matches, len(keywords)

# âœ¨ Highlight matching keywords in bold for visual clarity
def highlight_keywords(chunk, keywords):
    for kw in set(keywords):
        chunk = re.sub(rf'\b({kw})\b', r'**\1**', chunk, flags=re.IGNORECASE)
    return chunk

# âœ… Extract and store PDF text once per upload
if uploaded_pdf and "pdf_text" not in st.session_state:
    st.session_state.pdf_text = extract_text_from_pdf(uploaded_pdf)
    st.success("âœ… PDF uploaded and processed!")

# ğŸ’¬ Render past user and assistant messages
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# ğŸ§  Main question-answering logic (appears after PDF is uploaded)
if uploaded_pdf:
    question = st.chat_input("Ask a question about the PDF...")

    if question:
        st.session_state.messages.append({"role": "user", "content": question})  # Store user message

        keywords = get_keywords(question)  # Step 1: extract important keywords
        chunk, match_count, total_keywords = find_best_chunk(question, st.session_state.pdf_text)  # Step 2: find best match

        # Step 3: Compute trust score as % of keywords matched in best chunk
        trust_score = round((match_count / total_keywords) * 100, 2) if total_keywords > 0 else 0.0

        highlighted = highlight_keywords(chunk, keywords)  # Step 4: bold matched keywords

        # Step 5: Format assistant response and display in chat bubble
        response_md = f"ğŸ“˜ **Answer:**\n\n{highlighted}"

        with st.chat_message("assistant"):
            st.markdown(response_md)
            st.metric(label="Trust Score", value=f"{trust_score}%")  # Visual trust metric

        # Step 6: Save assistant message with trust score to history
        st.session_state.messages.append({
            "role": "assistant",
            "content": f"{response_md}\n\nğŸ“Š **Trust Score:** `{trust_score}%`"
        })

        st.rerun()  # Refresh to show updated messages

else:
    st.info("ğŸ“Œ Upload a PDF to get started.")
